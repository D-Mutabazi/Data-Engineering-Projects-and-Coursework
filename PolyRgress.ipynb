{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynmial regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolynomialRegression:\n",
    "     \n",
    "    def __init__(self, degree, learning_rate, iterations):\n",
    "        self.degree = degree\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.W = None\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "\n",
    "    # Function to transform X into polynomial features\n",
    "    def transform(self, X):\n",
    "        X_transform = np.ones((X.shape[0], 1))  # Add bias term (X^0)\n",
    "        for j in range(1, self.degree + 1):\n",
    "            X_transform = np.append(X_transform, np.power(X, j).reshape(-1, 1), axis=1)\n",
    "        return X_transform\n",
    "\n",
    "    # Function to normalize the features (save mean and std for normalization)\n",
    "    def normalize(self, X):\n",
    "        if self.mean is None or self.std is None:\n",
    "            self.mean = np.mean(X[:, 1:], axis=0)  # Mean excluding the bias term\n",
    "            self.std = np.std(X[:, 1:], axis=0)    # Standard deviation excluding the bias term\n",
    "        X[:, 1:] = (X[:, 1:] - self.mean) / self.std\n",
    "        return X\n",
    "\n",
    "    # Model training using gradient descent\n",
    "    def fit(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.m, self.n = self.X.shape\n",
    "\n",
    "        # Transform X into polynomial features\n",
    "        X_transform = self.transform(self.X)\n",
    "\n",
    "        # Normalize the transformed features\n",
    "        X_normalize = self.normalize(X_transform)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.W = np.zeros(X_normalize.shape[1])\n",
    "\n",
    "        # Gradient descent learning\n",
    "        for i in range(self.iterations):\n",
    "            h = self.predict(self.X)\n",
    "            error = h - self.Y\n",
    "            # Update weights\n",
    "            self.W = self.W - self.learning_rate * (1 / self.m) * np.dot(X_normalize.T, error)\n",
    "\n",
    "        return self\n",
    "\n",
    "    # Predict function using the learned weights\n",
    "    def predict(self, X):\n",
    "        # Transform and normalize X for prediction\n",
    "        X_transform = self.transform(X)\n",
    "        X_normalize = self.normalize(X_transform)\n",
    "        return np.dot(X_normalize, self.W)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and unifeature lag engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Time     Open     High      Low    Close  Volume\n",
      "0 2008-08-01  1.55575  1.55886  1.55142  1.55609  755330\n",
      "1 2008-08-03  1.55638  1.55790  1.55586  1.55658   76728\n",
      "2 2008-08-04  1.55662  1.56306  1.55526  1.55638  858293\n",
      "3 2008-08-05  1.55624  1.55646  1.54442  1.54640  858740\n",
      "4 2008-08-06  1.54650  1.55167  1.53956  1.54195  850798\n"
     ]
    }
   ],
   "source": [
    "# Data loading\n",
    "def data_loader(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    data['Time'] = pd.to_datetime(data['Time'],format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    return data\n",
    "\n",
    "#select one feature\n",
    "def featureEngineering(data, n_past=1):\n",
    "    X = []\n",
    "    Y= []\n",
    "    for i in range(n_past, len(data)):\n",
    "        X.append(data.iloc[i-n_past:i, -3].values)  # Select n_past number of rows for the closing price\n",
    "        Y.append(data.iloc[i, -3])  # The target value\n",
    "\n",
    "    feature_columns = [f'n_{i}' for i in range(1, n_past+1)]\n",
    "    X_df = pd.DataFrame(X, columns=feature_columns)\n",
    "    Y_df = pd.DataFrame(Y, columns=['response'])\n",
    "\n",
    "    data = pd.concat([X_df, Y_df], axis=1)\n",
    "\n",
    "    return data, X_df,Y_df\n",
    "\n",
    "filepath = './Data/EURUSD_D1.csv' \n",
    "datasetX = data_loader(filepath)\n",
    "\n",
    "print(datasetX.head())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
